"""
Forecast Service

Provides GPT-5 powered forecasting and business intelligence insights
based on AutoML model results.
"""

import json
import logging
import uuid
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Optional, Union

from app.config import settings
from app.services.azure_openai import AzureOpenAIService

logger = logging.getLogger(__name__)


class ForecastType(str, Enum):
    """Types of forecasts that can be generated."""
    TIMESERIES = "timeseries"
    INSIGHTS = "insights"
    BOTH = "both"


class ForecastStatus(str, Enum):
    """Forecast generation status states."""
    PENDING = "pending"
    GENERATING = "generating"
    COMPLETED = "completed"
    FAILED = "failed"


@dataclass
class KeyDriver:
    """A key business driver identified from AutoML results."""
    factor: str
    impact: str
    impact_score: float
    recommendation: str


@dataclass
class WhatIfScenario:
    """A hypothetical scenario and its predicted outcome."""
    scenario: str
    outcome: str
    confidence: float
    impact_direction: str  # 'positive', 'negative', 'neutral'


@dataclass
class BusinessInsights:
    """Business intelligence insights generated by GPT-5."""
    executive_summary: str
    key_drivers: List[KeyDriver]
    what_if_scenarios: List[WhatIfScenario]
    strategic_recommendations: List[str]
    risks_and_caveats: List[str]
    confidence_score: float


@dataclass
class TimeSeriesForecast:
    """Time series forecast predictions."""
    predictions: List[Dict[str, Any]]
    chart_data: Dict[str, Any]
    summary: Dict[str, Any]


@dataclass
class ForecastResult:
    """Complete forecast result including both time series and insights."""
    job_id: str
    automl_job_id: str
    forecast_type: str
    timeseries_forecast: Optional[TimeSeriesForecast]
    business_insights: BusinessInsights
    narrative: str
    generated_at: str
    model_used: str


@dataclass
class ForecastJob:
    """Tracks a forecast generation job."""
    job_id: str
    automl_job_id: str
    forecast_type: str
    status: ForecastStatus = ForecastStatus.PENDING
    progress_pct: int = 0
    message: str = ""
    result: Optional[ForecastResult] = None
    error: Optional[str] = None
    created_at: str = field(default_factory=lambda: datetime.utcnow().isoformat())


class ForecastService:
    """
    Service for generating GPT-5 powered forecasts and business insights.
    """

    def __init__(self, openai_service: Optional[AzureOpenAIService] = None):
        self.openai_service = openai_service or AzureOpenAIService()
        self._jobs: Dict[str, ForecastJob] = {}

        # Use GPT-5 (completion model) for advanced reasoning
        self.model_id = settings.AZURE_OPENAI_COMPLETION_MODEL_NAME

    async def generate_forecast(
        self,
        automl_job_id: str,
        automl_results: Dict[str, Any],
        forecast_type: str = "both",
        forecast_horizon: Optional[int] = None,
        time_column: Optional[str] = None,
        business_context: Optional[str] = None,
    ) -> ForecastResult:
        """
        Generate forecasts and business insights from AutoML results.

        Args:
            automl_job_id: ID of the completed AutoML job
            automl_results: Results from AutoGluon training
            forecast_type: 'timeseries', 'insights', or 'both'
            forecast_horizon: Number of periods to forecast (for timeseries)
            time_column: Name of time/date column (for timeseries)
            business_context: Optional additional context from user

        Returns:
            ForecastResult with predictions and insights
        """
        job_id = str(uuid.uuid4())
        job = ForecastJob(
            job_id=job_id,
            automl_job_id=automl_job_id,
            forecast_type=forecast_type,
            status=ForecastStatus.GENERATING,
            message="Generating business insights..."
        )
        self._jobs[job_id] = job

        try:
            # Extract key information from AutoML results
            task = automl_results.get("task", "classification")
            target_column = automl_results.get("target_column", "unknown")
            best_model = automl_results.get("best_model", "unknown")
            best_score = automl_results.get("best_score", 0)
            eval_metric = automl_results.get("eval_metric", "accuracy")
            feature_importance = automl_results.get("feature_importance", {})
            leaderboard = automl_results.get("leaderboard", [])
            num_rows = automl_results.get("num_rows_train", 0)
            num_features = automl_results.get("num_features", 0)
            predictions_sample = automl_results.get("predictions_sample", [])
            existing_insights = automl_results.get("insights", {})

            # Generate business insights using GPT-5
            job.progress_pct = 30
            job.message = "Analyzing model performance..."

            business_insights = await self._generate_business_insights(
                task=task,
                target_column=target_column,
                best_model=best_model,
                best_score=best_score,
                eval_metric=eval_metric,
                feature_importance=feature_importance,
                leaderboard=leaderboard,
                num_rows=num_rows,
                num_features=num_features,
                predictions_sample=predictions_sample,
                existing_insights=existing_insights,
                business_context=business_context,
            )

            job.progress_pct = 70
            job.message = "Generating strategic narrative..."

            # Generate time series forecast if applicable
            timeseries_forecast = None
            if forecast_type in ["timeseries", "both"] and time_column:
                job.message = "Generating time series forecasts..."
                timeseries_forecast = await self._generate_timeseries_forecast(
                    automl_results=automl_results,
                    time_column=time_column,
                    horizon=forecast_horizon or 30,
                )

            job.progress_pct = 90
            job.message = "Finalizing results..."

            # Generate overall narrative
            narrative = await self._generate_narrative(
                business_insights=business_insights,
                timeseries_forecast=timeseries_forecast,
                task=task,
                target_column=target_column,
                business_context=business_context,
            )

            # Create result
            result = ForecastResult(
                job_id=job_id,
                automl_job_id=automl_job_id,
                forecast_type=forecast_type,
                timeseries_forecast=timeseries_forecast,
                business_insights=business_insights,
                narrative=narrative,
                generated_at=datetime.utcnow().isoformat(),
                model_used=self.model_id,
            )

            job.status = ForecastStatus.COMPLETED
            job.progress_pct = 100
            job.message = "Forecast generation complete"
            job.result = result

            return result

        except Exception as e:
            logger.error(f"Error generating forecast: {e}")
            job.status = ForecastStatus.FAILED
            job.error = str(e)
            raise

    async def _generate_business_insights(
        self,
        task: str,
        target_column: str,
        best_model: str,
        best_score: float,
        eval_metric: str,
        feature_importance: Dict[str, float],
        leaderboard: List[Dict],
        num_rows: int,
        num_features: int,
        predictions_sample: List[Dict],
        existing_insights: Dict,
        business_context: Optional[str],
    ) -> BusinessInsights:
        """Generate business intelligence insights using GPT-5."""

        # Sort features by importance
        top_features = sorted(
            feature_importance.items(),
            key=lambda x: abs(x[1]),
            reverse=True
        )[:10]

        # Top models from leaderboard
        top_models = leaderboard[:5] if leaderboard else []

        # Build prompt
        system_prompt = """You are a senior business analyst and data science expert.
Your role is to translate technical machine learning results into actionable business insights.
Always provide specific, actionable recommendations that business stakeholders can understand and implement.
Focus on business value and ROI implications of the findings."""

        user_prompt = f"""Analyze the following AutoML results and generate comprehensive business insights.

## Model Performance
- Task: {task}
- Target Variable: {target_column}
- Best Model: {best_model}
- Performance Score ({eval_metric}): {best_score:.4f}
- Training Data: {num_rows:,} rows, {num_features} features

## Top Features (by importance)
{json.dumps(dict(top_features), indent=2)}

## Model Leaderboard (Top 5)
{json.dumps(top_models, indent=2)}

## Sample Predictions
{json.dumps(predictions_sample[:5] if predictions_sample else [], indent=2)}

{f"## Additional Business Context: {business_context}" if business_context else ""}

Generate a JSON response with the following structure:
{{
    "executive_summary": "2-3 sentence executive summary for C-suite",
    "key_drivers": [
        {{
            "factor": "feature name",
            "impact": "description of business impact",
            "impact_score": 0.0-1.0,
            "recommendation": "specific action to take"
        }}
    ],
    "what_if_scenarios": [
        {{
            "scenario": "what-if scenario description",
            "outcome": "predicted outcome",
            "confidence": 0.0-1.0,
            "impact_direction": "positive/negative/neutral"
        }}
    ],
    "strategic_recommendations": ["recommendation 1", "recommendation 2", ...],
    "risks_and_caveats": ["caveat 1", "caveat 2", ...],
    "confidence_score": 0.0-1.0
}}

Provide 3-5 key drivers, 2-3 what-if scenarios, 3-5 strategic recommendations, and 2-4 risks/caveats.
Base your insights on the actual model performance and feature importance data provided."""

        try:
            response = await self.openai_service.generate_response(
                prompt=user_prompt,
                system_prompt=system_prompt,
                response_format="json",
                model_id=self.model_id,
            )

            if isinstance(response, str):
                # Try to extract JSON from response
                response = self._extract_json(response)

            # Parse and validate response
            return BusinessInsights(
                executive_summary=response.get("executive_summary", "Analysis complete."),
                key_drivers=[
                    KeyDriver(**driver) for driver in response.get("key_drivers", [])
                ],
                what_if_scenarios=[
                    WhatIfScenario(**scenario) for scenario in response.get("what_if_scenarios", [])
                ],
                strategic_recommendations=response.get("strategic_recommendations", []),
                risks_and_caveats=response.get("risks_and_caveats", []),
                confidence_score=response.get("confidence_score", 0.7),
            )

        except Exception as e:
            logger.error(f"Error generating business insights: {e}")
            # Return fallback insights
            return self._generate_fallback_insights(
                task, target_column, best_model, best_score, eval_metric, top_features
            )

    def _generate_fallback_insights(
        self,
        task: str,
        target_column: str,
        best_model: str,
        best_score: float,
        eval_metric: str,
        top_features: List,
    ) -> BusinessInsights:
        """Generate basic insights when GPT-5 is unavailable."""

        # Interpret score
        if task == "classification":
            if best_score >= 0.9:
                score_quality = "excellent"
            elif best_score >= 0.8:
                score_quality = "good"
            elif best_score >= 0.7:
                score_quality = "moderate"
            else:
                score_quality = "needs improvement"
        else:  # regression
            if best_score >= 0.8:
                score_quality = "excellent"
            elif best_score >= 0.6:
                score_quality = "good"
            elif best_score >= 0.4:
                score_quality = "moderate"
            else:
                score_quality = "needs improvement"

        executive_summary = (
            f"The {best_model} model achieved {score_quality} performance "
            f"({eval_metric}: {best_score:.2%}) for predicting {target_column}. "
            f"The top predictive factors are: {', '.join([f[0] for f in top_features[:3]])}."
        )

        key_drivers = [
            KeyDriver(
                factor=feature,
                impact=f"This feature contributes {importance:.1%} to predictions",
                impact_score=importance,
                recommendation=f"Monitor and optimize {feature} to improve outcomes"
            )
            for feature, importance in top_features[:5]
        ]

        return BusinessInsights(
            executive_summary=executive_summary,
            key_drivers=key_drivers,
            what_if_scenarios=[
                WhatIfScenario(
                    scenario=f"Improving top feature {top_features[0][0]} by 10%",
                    outcome="Could improve prediction accuracy",
                    confidence=0.6,
                    impact_direction="positive"
                )
            ],
            strategic_recommendations=[
                f"Focus on improving data quality for top features",
                f"Consider A/B testing strategies based on model predictions",
                f"Set up monitoring for {target_column} predictions"
            ],
            risks_and_caveats=[
                "Model performance may vary on new data distributions",
                "Feature importance rankings are relative to this dataset",
                "Consider collecting more data for edge cases"
            ],
            confidence_score=0.5,
        )

    async def _generate_timeseries_forecast(
        self,
        automl_results: Dict[str, Any],
        time_column: str,
        horizon: int,
    ) -> Optional[TimeSeriesForecast]:
        """Generate time series forecast if time column is available."""
        # Note: This is a placeholder for actual time series forecasting
        # In production, this would use the trained model for predictions

        logger.info(f"Time series forecasting requested for {time_column} with horizon {horizon}")

        # For now, return None - time series forecasting requires
        # access to actual data and the trained model
        return None

    async def _generate_narrative(
        self,
        business_insights: BusinessInsights,
        timeseries_forecast: Optional[TimeSeriesForecast],
        task: str,
        target_column: str,
        business_context: Optional[str],
    ) -> str:
        """Generate a natural language narrative summarizing all insights."""

        system_prompt = """You are a business intelligence writer. Create clear, engaging narratives
that explain data science results to business stakeholders. Write in a professional but accessible tone."""

        narrative_parts = [
            f"## Analysis Summary for {target_column}",
            "",
            business_insights.executive_summary,
            "",
            "### Key Drivers",
        ]

        for driver in business_insights.key_drivers[:3]:
            narrative_parts.append(f"- **{driver.factor}**: {driver.impact}")

        narrative_parts.extend([
            "",
            "### Strategic Recommendations",
        ])

        for rec in business_insights.strategic_recommendations[:3]:
            narrative_parts.append(f"1. {rec}")

        if business_insights.risks_and_caveats:
            narrative_parts.extend([
                "",
                "### Important Considerations",
            ])
            for caveat in business_insights.risks_and_caveats[:2]:
                narrative_parts.append(f"- {caveat}")

        return "\n".join(narrative_parts)

    def _extract_json(self, text: str) -> Dict:
        """Extract JSON from text that may contain markdown code blocks."""
        import re

        # Try to find JSON in code blocks
        json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', text, re.DOTALL)
        if json_match:
            return json.loads(json_match.group(1))

        # Try to parse the whole text as JSON
        try:
            return json.loads(text)
        except json.JSONDecodeError:
            pass

        # Try to find JSON object in text
        json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', text, re.DOTALL)
        if json_match:
            try:
                return json.loads(json_match.group())
            except json.JSONDecodeError:
                pass

        return {}

    def get_job(self, job_id: str) -> Optional[ForecastJob]:
        """Get a forecast job by ID."""
        return self._jobs.get(job_id)

    def get_jobs_for_automl(self, automl_job_id: str) -> List[ForecastJob]:
        """Get all forecast jobs for an AutoML job."""
        return [
            job for job in self._jobs.values()
            if job.automl_job_id == automl_job_id
        ]

    def to_dict(self, result: ForecastResult) -> Dict[str, Any]:
        """Convert ForecastResult to dictionary for API response."""
        return {
            "job_id": result.job_id,
            "automl_job_id": result.automl_job_id,
            "forecast_type": result.forecast_type,
            "timeseries_forecast": self._timeseries_to_dict(result.timeseries_forecast),
            "business_insights": self._insights_to_dict(result.business_insights),
            "narrative": result.narrative,
            "generated_at": result.generated_at,
            "model_used": result.model_used,
        }

    def _timeseries_to_dict(self, forecast: Optional[TimeSeriesForecast]) -> Optional[Dict]:
        """Convert TimeSeriesForecast to dictionary."""
        if not forecast:
            return None
        return {
            "predictions": forecast.predictions,
            "chart_data": forecast.chart_data,
            "summary": forecast.summary,
        }

    def _insights_to_dict(self, insights: BusinessInsights) -> Dict:
        """Convert BusinessInsights to dictionary."""
        return {
            "executive_summary": insights.executive_summary,
            "key_drivers": [
                {
                    "factor": d.factor,
                    "impact": d.impact,
                    "impact_score": d.impact_score,
                    "recommendation": d.recommendation,
                }
                for d in insights.key_drivers
            ],
            "what_if_scenarios": [
                {
                    "scenario": s.scenario,
                    "outcome": s.outcome,
                    "confidence": s.confidence,
                    "impact_direction": s.impact_direction,
                }
                for s in insights.what_if_scenarios
            ],
            "strategic_recommendations": insights.strategic_recommendations,
            "risks_and_caveats": insights.risks_and_caveats,
            "confidence_score": insights.confidence_score,
        }


# Singleton instance
forecast_service = ForecastService()
